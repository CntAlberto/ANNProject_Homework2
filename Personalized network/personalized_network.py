# -*- coding: utf-8 -*-
"""Personalized_Network.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17cbEK4dJgdq709mgIN-aCxtFUiZ4uGtK
"""

import numpy as np
import tensorflow as tf
from scipy.ndimage import rotate
from skimage.transform import warp, AffineTransform, resize
from tensorflow.keras import layers as tfkl
from sklearn.model_selection import train_test_split
from tensorflow.python.ops.numpy_ops.np_dtypes import uint8

#----------------------------- Load Data ---------------------------------------

print("Loading dataset...")

data = np.load("training_set.npz")

training_set = data["training_set"]
X_train = training_set[:, 0]
y_train = training_set[:, 1]

X_test = data["test_set"]

print("Dataset loaded!")
print("Setting classes...")

category_map = {
   0: 0,  # Background
   1: 1,  # Soil
   2: 2,  # Bedrock
   3: 3,  # Sand
   4: 4,  # Big rock
}

NUM_CLASSES = len(set(category_map.values()))           # Calculate the correct number of classes after mapping
print("removing outlayers")

mask_alien = y_train[142]                               # Alien image mask

X_cleaned = []                                          # Initialize lists to store the cleaned dataset
y_cleaned = []

for idx, mask in enumerate(y_train):
   if np.array_equal(mask, mask_alien):                 # Check if the mask is the alien image mask
       continue                                         # If it is a duplicate mask, skip this image and mask

   X_cleaned.append(X_train[idx])                       # If it's not a duplicate, add the image and its corresponding mask to the cleaned dataset
   y_cleaned.append(mask)

X_cleaned = np.array(X_cleaned)                         # Convert the cleaned lists to numpy arrays
y_cleaned = np.array(y_cleaned)

print("outlayers removed")
print("Classes setted!")

#--------------------------- Train-Val Split -----------------------------------

print("Splitting dataset...")

X_train, X_val, y_train, y_val = train_test_split(X_cleaned, y_cleaned, test_size=0.1, random_state=42, shuffle=True)

print("Data splitted!")

#------------------------ Personalized Network --------------------------------------> Since multi-scale analysis through dilated convolutions gave good performance
                                                                                     # we decided to try and write a network in order to explore patterns at many different
def conv_block(input_layer,kernel_size,dropout,filters, dilation_rate):              # beginning from the whole image
  c1 = tfkl.Conv2D(filters , kernel_size=kernel_size , padding='same',dilation_rate = dilation_rate, kernel_initializer="he_normal")(input_layer)
  c1 = tfkl.BatchNormalization()(c1)
  c1 = tfkl.ReLU()(c1)
  c1 = tfkl.Dropout(dropout)(c1)
  print("blocco conv:",c1.shape)
  return c1

def B3_block(input,kernel,dropout,filters):
  glob = tfkl.AveragePooling2D(pool_size=(16,32))(input)
  glob_up = tfkl.UpSampling2D(size = (16,32), interpolation = 'bilinear')(glob)
  B3a = conv_block(input,kernel,dropout,filters,1)
  B3b = conv_block(input,kernel,dropout,filters,2)
  B3c = conv_block(input,kernel,dropout,filters,3)

  B3 = tfkl.Add()([glob_up,B3a,B3b,B3c])
  B3 = conv_block(B3,kernel,dropout,filters,1)
  up = tfkl.UpSampling2D(size = (2,2), interpolation = 'bilinear')(B3)
  B3f = conv_block( up , 1 , dropout , 64 , 1 )

  return B3f

def B2_block(input,kernel,dropout,filters):
  B2a = conv_block(input,kernel,dropout,filters,1)
  B2b = conv_block(input,kernel,dropout,filters,2)
  B2c = conv_block(input,kernel,dropout,filters,3)

  return B2a,B2b,B2c

def B1_block(input,kernel,dropout,filters):
  B1a = conv_block(input,kernel,dropout,filters,1)
  B1b = conv_block(input,kernel,dropout,filters,2)
  B1c = conv_block(input,kernel,dropout,filters,3)

  return B1a,B1b,B1c

def model(input, kernel_size):                                                  # Each input image is convolved on 27 different paths through each possible combination
  print("input:",input)                                                         # of normal convolutional filters and dilated ones with rates of 1 and 2
  filters = 32
  dropout = 0

  input_layer = tfkl.Input(shape=input, name='input_layer')                     #64 x 128 x 1
  print("input:",input_layer.shape)

  #------------ Layer 1 ----------------                                        #---> 3 convolutional paths

  B1a,B1b,B1c = B1_block( input_layer , kernel_size , dropout , filters )       #64 x 128 x 32

  pool1a = tfkl.MaxPooling2D()(B1a)                                             #32 x 64 x 32
  pool1b = tfkl.MaxPooling2D()(B1b)
  pool1c = tfkl.MaxPooling2D()(B1c)

  #------------ Layer 2 ----------------                                        #---> 3x3 paths

  B2aa,B2ab,B2ac = B2_block( pool1a , kernel_size , dropout , filters*2 )       #32 x 64 x 64
  B2ba,B2bb,B2bc = B2_block( pool1b , kernel_size , dropout , filters*2 )
  B2ca,B2cb,B2cc = B2_block( pool1c , kernel_size , dropout , filters*2 )

  pool2aa = tfkl.MaxPooling2D()(B2aa)                                           #16 x 32 x 64
  pool2ab = tfkl.MaxPooling2D()(B2ab)
  pool2ac = tfkl.MaxPooling2D()(B2ac)

  pool2ba = tfkl.MaxPooling2D()(B2ba)
  pool2bb = tfkl.MaxPooling2D()(B2bb)
  pool2bc = tfkl.MaxPooling2D()(B2bc)

  pool2ca = tfkl.MaxPooling2D()(B2ca)
  pool2cb = tfkl.MaxPooling2D()(B2cb)
  pool2cc = tfkl.MaxPooling2D()(B2cc)

  #------------ Layer 3 ----------------                                        #---> 3x3x3 paths

  B3aa = B3_block( pool2aa , kernel_size , dropout , filters*4 )                #32 x 64 x 64
  B3ab = B3_block( pool2ab , kernel_size , dropout , filters*4 )
  B3ac = B3_block( pool2ac , kernel_size , dropout , filters*4 )

  B3ba = B3_block( pool2ba , kernel_size , dropout , filters*4 )
  B3bb = B3_block( pool2bb , kernel_size , dropout , filters*4 )
  B3bc = B3_block( pool2bc , kernel_size , dropout , filters*4 )

  B3ca = B3_block( pool2ca , kernel_size , dropout , filters*4 )
  B3cb = B3_block( pool2cb , kernel_size , dropout , filters*4 )
  B3cc = B3_block( pool2cc , kernel_size , dropout , filters*4 )

  #------- Skip connection 1 -----------

  skip1aa = tfkl.Add()([up1aa, B2aa])                                           #32 x 64 x 64
  skip1ab = tfkl.Add()([up1ab, B2ab])
  skip1ac = tfkl.Add()([up1ac, B2ac])

  skip1ba = tfkl.Add()([up1ba, B2ba])
  skip1bb = tfkl.Add()([up1bb, B2bb])
  skip1bc = tfkl.Add()([up1bc, B2bc])

  skip1ca = tfkl.Add()([up1ca, B2ca])
  skip1cb = tfkl.Add()([up1cb, B2cb])
  skip1cc = tfkl.Add()([up1cc, B2cc])

  #--- Convolution skip connections ----

  c1aa = conv_block( skip1aa , kernel_size , dropout , filters*2 , 1 )          #32 x 64 x 64
  c1ab = conv_block( skip1ab , kernel_size , dropout , filters*2 , 1 )
  c1ac = conv_block( skip1ac , kernel_size , dropout , filters*2 , 1 )

  c1ba = conv_block( skip1ba , kernel_size , dropout , filters*2 , 1 )
  c1bb = conv_block( skip1bb , kernel_size , dropout , filters*2 , 1 )
  c1bc = conv_block( skip1bc , kernel_size , dropout , filters*2 , 1 )

  c1ca = conv_block( skip1ca , kernel_size , dropout , filters*2 , 1 )
  c2cb = conv_block( skip1cb , kernel_size , dropout , filters*2 , 1 )
  c3cc = conv_block( skip1cc , kernel_size , dropout , filters*2 , 1 )

  #-------- integrazione info B3 ---------

  int1a = tfkl.Add([c1aa,c1ab,c1ac])                                            #32 x 64 x 64
  int1b = tfkl.Add([c1ba,c1bb,c1bc])
  int1c = tfkl.Add([c1ca,c2cb,c3cc])

  #----- convolution info integrate -----

  c2a = conv_block( int1a , kernel_size , dropout , filters*2 , 1 )             #32 x 64 x 64
  c2b = conv_block( int1b , kernel_size , dropout , filters*2 , 1 )
  c2c = conv_block( int1c , kernel_size , dropout , filters*2 , 1 )

  #----------- Upsampling 2 ------------

  up2a = tfkl.UpSampling2D(size = (2,2), interpolation = 'bilinear')(c2a)       #64 x 128 x 64
  up2b = tfkl.UpSampling2D(size = (2,2), interpolation = 'bilinear')(c2b)
  up2c = tfkl.UpSampling2D(size = (2,2), interpolation = 'bilinear')(c2c)

  c_up2a = conv_block( up2a , 1 , dropout , filters , 1 )                       #64 x 128 x 32
  c_up2b = conv_block( up2b , 1 , dropout , filters , 1 )
  c_up2c = conv_block( up2c , 1 , dropout , filters , 1 )

  #--------- skip connection 2 -----------

  skip2a = tfkl.Add()([up2a, B1a])                                              #64 x 128 x 32
  skip2b = tfkl.Add()([up2b, B1b])
  skip2c = tfkl.Add()([up2c, B1c])

  #----- convolution skip connections -----

  c3a = conv_block( skip2a , kernel_size , dropout , filters , 1 )              #64 x 128 x 32
  c3b = conv_block( skip2b , kernel_size , dropout , filters , 1 )
  c3c = conv_block( skip2c , kernel_size , dropout , filters , 1 )

  #----- Integrazione info B2 ---------

  int2a = tfkl.Add([c3a,c3b,c3c])                                               #64 x 128 x 32

  #----- convoluzione info integrate -----

  c3 = conv_block( int2a , kernel_size , dropout , filters , 1 )

  output_layer = tfkl.Conv2D( 5 , kernel_size=1, padding='same', activation="softmax")(c3)

  model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
  return model


model = model((64,128,1), 3)                                                    # Very low performance in respect to the computational cost