# -*- coding: utf-8 -*-
"""UNet-V0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CfJbaMN8hJY2--z1QTAdANOb-lLyXdKm
"""

from datetime import datetime
import numpy as np
import tensorflow as tf
from tensorflow import keras as tfk
from tensorflow.keras import layers as tfkl
from sklearn.model_selection import train_test_split

# ----------------------------- Dataset loading --------------------------------

print("Loading dataset...")

data = np.load("training_set.npz")

training_set = data["training_set"]
X = training_set[:, 0]
y = training_set[:, 1]

X_test = data["test_set"]

print("Dataset loaded!")

# ------------------- Class setting and outlayers removal-----------------------

print("Setting classes...")

category_map = {
    0: 0,  # Background
    1: 1,  # Soil
    2: 2,  # Bedrock
    3: 3,  # Sand
    4: 4,  # Big rock
}

unet_block_num_classes = len(set(category_map.values()))          # Calculate the correct number of classes after mapping
print("removing outlayers")

mask_alien = y[142]                                               # Outliers removal (Alien)

X_cleaned = []                                                    # Initialize lists to store the cleaned dataset
y_cleaned = []

for idx, mask in enumerate(y):
    if np.array_equal(mask, mask_alien):
        continue

    X_cleaned.append(X[idx])                                      # If it's not a duplicate, add the image and its corresponding mask to the cleaned dataset
    y_cleaned.append(mask)

X_cleaned = np.array(X_cleaned)                                   # Convert the cleaned lists to numpy arrays
y_cleaned = np.array(y_cleaned)

print("outlayers removed")
print("Classes setted!")

# -------------------------------------------train-val split----------------------------------------------

print("Splitting dataset...")

X_train, X_val, y_train, y_val = train_test_split(X_cleaned, y_cleaned, test_size=0.1, random_state=42, shuffle=True)    # Split the dataset into training and validation sets

print("Data splitted!")

# ------------------------------------------- Model definition ----------------------------------------------

print("Building model...")

# define parameters for Unet initialization

unet_block_kernel_size = 3
unet_block_activation = 'relu'
unet_block_stack = 2
unet_block_input_shape = (64, 128, 1)
unet_block_filters = 8
unet_output_kernel_size = 1


def unet_block(input_tensor, filters, kernel_size, activation, stack):              # Define a Unet block with inside the initialization of the layers
    x = input_tensor

    for i in range(stack):                                                          # Apply a sequence of Conv2D, Batch Normalisation, and Activation layers for the specified number of stacks
        x = tfkl.Conv2D(filters * 2, kernel_size=kernel_size, padding='same')(x)
        x = tfkl.BatchNormalization()(x)
        x = tfkl.Activation(activation)(x)

    return x

def get_unet_model(input_shape, num_classes):                                        # Define the network using Unet blocks and parameters
    input_layer = tfkl.Input(shape=input_shape, name='input_layer')

    # Downsampling path

    down_block_1 = unet_block(input_layer, unet_block_filters, unet_block_kernel_size, unet_block_activation,
                              unet_block_stack)
    d1 = tfkl.MaxPooling2D()(down_block_1)

    down_block_2 = unet_block(d1, unet_block_filters * 2, unet_block_kernel_size, unet_block_activation,
                              unet_block_stack)
    d2 = tfkl.MaxPooling2D()(down_block_2)

    # Bottleneck

    bottleneck = unet_block(d2, unet_block_filters * 8, unet_block_kernel_size, unet_block_activation, unet_block_stack)

    # Upsampling path

    u1 = tfkl.UpSampling2D()(bottleneck)
    u1 = tfkl.Concatenate()([u1, down_block_2])
    u1 = unet_block(u1, unet_block_filters * 2, unet_block_kernel_size, unet_block_activation, unet_block_stack)

    u2 = tfkl.UpSampling2D()(u1)
    u2 = tfkl.Concatenate()([u2, down_block_1])
    u2 = unet_block(u2, unet_block_filters, unet_block_kernel_size, unet_block_activation, unet_block_stack)

    # Output Layer

    output_layer = tfkl.Conv2D(num_classes, kernel_size=unet_output_kernel_size, padding='same', activation='softmax')(u2)

    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
    return model


model = get_unet_model(unet_block_input_shape, unet_block_num_classes)

print("Model built!")

print("defining custom loss function...")

#-------------------- Mean IoU metric definition -------------------------------

def iou(y_true, y_pred):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)

    intersection = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true + y_pred) - intersection

    return intersection / (union + tf.keras.backend.epsilon())


def iou_multi_class(y_true, y_pred, num_classes):
    iou_per_class = []
    y_pred = tf.argmax(y_pred, axis=-1)
    for i in range(num_classes):
        y_true_class = tf.equal(y_true, i)
        y_pred_class = tf.equal(y_pred, i)
        iou_per_class.append(iou(y_true_class, y_pred_class))

    return tf.reduce_mean(iou_per_class)

print("custom loss function defined!")

# ------------------- Parameters setting for compiling -------------------------

print("Compiling model...")

patience = 10
epochs = 400

mean_iou = tfk.metrics.MeanIoU(num_classes=unet_block_num_classes, ignore_class=0, sparse_y_pred=False)   # Define the MeanIoU ignoring the background class

print("Parameters setted!")

# --------------------------- Model compiling ----------------------------------

model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=[mean_iou])

print("Model compiled!")

# Setup callbacks

early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_mean_io_u',
    mode='max',
    patience=patience,
    restore_best_weights=True
)

# ------------------------------ Model training --------------------------------

print("Training model...")
# Train the model
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, callbacks=[early_stopping])

# Calculate and print the final validation accuracy
y_predicted = model.predict(X_val)
final_val_meanIoU = iou_multi_class(y_val, y_predicted, unet_block_num_classes)

print("Model trained!")
print(f'Final validation Mean Intersection Over Union: {final_val_meanIoU}')

# ---------------------------- Model saving ------------------------------------
timestep_str = datetime.now().strftime("%y%m%d_%H%M%S")
model_filename = f"model_{timestep_str}.keras"

model.save(model_filename)
del model

print("Model saved!")